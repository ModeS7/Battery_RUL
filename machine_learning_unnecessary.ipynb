{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.364175Z",
     "start_time": "2025-01-15T20:48:20.267108Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.428175Z",
     "start_time": "2025-01-15T20:48:34.369173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('data/Battery_RUL_cleaned.csv')\n",
    "df = df[df.columns[1:]]  # Remove the first column\n",
    "\n",
    "# Last column is the target variable\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "\n",
    "# Create data loaders\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "1d8f90ff8634e989",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.779176Z",
     "start_time": "2025-01-15T20:48:34.606176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# Define models\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, h_size):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(7, h_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size, h_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size//2, h_size//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size//4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "class NN(nn.Module):\n",
    "    def __init__(self, h_size, d_rate):\n",
    "        super().__init__()\n",
    "        self.Flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(7, h_size),\n",
    "            nn.BatchNorm1d(h_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(d_rate),\n",
    "            nn.Linear(h_size, h_size//2),\n",
    "            nn.BatchNorm1d(h_size//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size//2, h_size//4),\n",
    "            nn.BatchNorm1d(h_size//4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h_size//4, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.Flatten(x)\n",
    "        logit = self.linear_relu_stack(x)\n",
    "        return logit\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "model = NN(512, 0.2).to(device)\n",
    "#model = NeuralNetwork(512).to(device)\n",
    "print(model)"
   ],
   "id": "6e7a1a15a9029c0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "NN(\n",
      "  (Flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=7, out_features=512, bias=True)\n",
      "    (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.2, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.890176Z",
     "start_time": "2025-01-15T20:48:34.875198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ],
   "id": "ea8b87d719a1a69c",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.953178Z",
     "start_time": "2025-01-15T20:48:34.939177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(dataloader, model, loss1, loss2, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        X, y = batch\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = 0.7 * loss1(pred.squeeze(), y) + 0.3 * loss2(pred.squeeze(), y)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Log the loss\n",
    "        writer.add_scalar('Training Loss', loss.item(), epoch)\n",
    "        return loss\n"
   ],
   "id": "34739c3dbd34ef58",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:48:34.969176Z",
     "start_time": "2025-01-15T20:48:34.962180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(dataloader, model, loss1, loss2, epoch):\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            X, y = batch\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X).squeeze()\n",
    "            test_loss += loss1(pred, y).item() + loss2(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "\n",
    "    # Log the loss\n",
    "    writer.add_scalar('Test Loss', test_loss, epoch)\n",
    "    return test_loss\n"
   ],
   "id": "25961fea9b78cc4a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T20:50:40.472910Z",
     "start_time": "2025-01-15T20:48:34.986180Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize TensorBoard writer\n",
    "writer = SummaryWriter('runs/experiment_4')\n",
    "\n",
    "loss1 = nn.L1Loss()\n",
    "loss2 = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-1)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.8)\n",
    "epochs = 1500\n",
    "\n",
    "# Initialize early stopping\n",
    "early_stopping = EarlyStopping(patience=50, min_delta=0.01)\n",
    "\n",
    "pbar = tqdm(range(epochs))\n",
    "for t in pbar:\n",
    "    train_loss = train(train_dataloader, model, loss1, loss2, optimizer, t)\n",
    "    test_loss = test(test_dataloader, model, loss1, loss2, t)\n",
    "    scheduler.step()\n",
    "    pbar.set_description(f\"Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "    # Check for early stopping\n",
    "    #early_stopping(test_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping\")\n",
    "        break\n",
    "\n",
    "print(\"Done!\")\n",
    "torch.save(model.state_dict(), 'models/model.pt')  # Save only the state_dict\n",
    "\n",
    "# Close the TensorBoard writer\n",
    "writer.close()\n",
    "\n",
    "model.eval()\n",
    "X, y = next(iter(test_dataloader))\n",
    "X, y = X.to(device), y.to(device)\n",
    "with torch.no_grad():\n",
    "    pred = model(X)\n",
    "    predicted, actual = pred[0], y[0]\n",
    "    print(f'Input: \"{X[0]}\", Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ],
   "id": "8cb3510bee6b1130",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Loss: 33.6796, Test Loss: 69.4819: 100%|██████████| 1500/1500 [02:05<00:00, 11.97it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Input: \"tensor([1.8370e+03, 5.7400e+02, 3.9660e+00, 3.4860e+00, 3.8748e+03, 4.7964e+03,\n",
      "        8.6528e+03], device='cuda:0')\", Predicted: \"tensor([773.5727], device='cuda:0')\", Actual: \"827.0\"\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
