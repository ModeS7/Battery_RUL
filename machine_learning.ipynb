{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T17:58:04.564809Z",
     "start_time": "2025-01-16T17:58:04.547810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary modules\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer"
   ],
   "id": "e8c056c1d9f28e8d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T17:58:06.087849Z",
     "start_time": "2025-01-16T17:58:06.063850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load CSV data into a pandas DataFrame\n",
    "df = pd.read_csv('data/Battery_RUL_cleaned.csv')\n",
    "#df = pd.read_csv('data/Battery_RUL.csv')\n",
    "df = df[df.columns[1:]]  # Remove the first column\n",
    "\n",
    "# Last column is the target variable\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "d1aeaf59b6a1f90e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-16T18:10:48.691850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the hyperparameter grid\n",
    "param_grid = [\n",
    "    {'C': [1e+4, 1e+5, 1e+6], 'kernel': ['rbf'], 'gamma': [1e-6, 1e-5, 1e-4]}]\n",
    "# Define the scoring dictionary\n",
    "scoring = {\n",
    "    'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'MSE': make_scorer(mean_squared_error, greater_is_better=False)\n",
    "}\n",
    "# Initialize and train the SVM model\n",
    "# model = SVR(kernel='linear', C=0.1, epsilon=0.2)\n",
    "# Mean Absolute Error: 35.6885\n",
    "# Mean Squared Error: 2358.7762\n",
    "model = GridSearchCV(SVR(), param_grid, cv=5, scoring=scoring, refit='MSE', n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract the results and convert to a DataFrame\n",
    "results = pd.DataFrame(model.cv_results_)\n",
    "results.to_csv('data/SVR1.csv', index=False)\n",
    "\n",
    "# Create a single plot with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot MSE on the primary y-axis\n",
    "for kernel in results['param_kernel'].unique():\n",
    "    subset = results[results['param_kernel'] == kernel]\n",
    "    ax1.plot(subset['param_C'], -subset['mean_test_MSE'], label=f'MSE - Kernel: {kernel}', linestyle='-', marker='o')\n",
    "ax1.set_xlabel('C')\n",
    "ax1.set_ylabel('Mean Squared Error')\n",
    "ax1.set_xscale('log')\n",
    "ax1.legend(loc='upper left')\n",
    "ax1.set_title('Grid Search Results (MSE and MAE)')\n",
    "\n",
    "# Create a secondary y-axis for MAE\n",
    "ax2 = ax1.twinx()\n",
    "for kernel in results['param_kernel'].unique():\n",
    "    subset = results[results['param_kernel'] == kernel]\n",
    "    ax2.plot(subset['param_C'], -subset['mean_test_MAE'], label=f'MAE - Kernel: {kernel}', linestyle='--', marker='x')\n",
    "ax2.set_ylabel('Mean Absolute Error')\n",
    "ax2.legend(loc='upper right')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Get the best model\n",
    "best_model = model.best_estimator_\n",
    "print(best_model)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "# first run: 39.9814"
   ],
   "id": "2092498e7cfdfb6b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T17:38:25.892291Z",
     "start_time": "2025-01-16T17:38:21.432276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize and train the Random Forest model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=1, n_jobs=-1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "# first run: 8.0703\n",
    "# best run: 7.9780"
   ],
   "id": "7ac2e03657bdb3e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7.9780\n",
      "Mean Squared Error: 236.9407\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:47:05.149350Z",
     "start_time": "2025-01-16T11:46:48.415305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize and train the XGBoost model\n",
    "model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=10000, learning_rate=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "# first run: 15.3975\n",
    "# best run: 7.9632"
   ],
   "id": "60f9f9bd5531afce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 7.9632\n",
      "Mean Squared Error: 210.3707\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-16T11:52:31.063300Z",
     "start_time": "2025-01-16T11:51:45.056392Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# first run: 39.9814"
   ],
   "id": "4d3238d066f679f4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 48.1311\n",
      "Mean Squared Error: 3505.6304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
